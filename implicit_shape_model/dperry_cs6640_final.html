<html>
<head>
<title>CS6640 Danny Perry - Final Project - Implicit Shape Model Using Hough Transform</title>
</head>
<!-- libs -->
<script type="text/javascript" src="LaTeXMathML.js"></script>

<!-- css -->
<!--
<link rel="stylesheet" type="text/css" href="style.css"></link>
-->
<style>
img {width:500px;}
#image {width:300px;}
#section {width: 900px;}
table {max-width:810px;}
p {background: #ccc; padding: 9px; border-radius: 15px;}
</style>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35081386-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


<body>

<div id="section">
<h1>Final Project - Implicit Shape Model Using Hough Transforms</h1>
<h2>Daniel Perry</h2>
<div id="section">
<div style="background: #ccc; padding: 9px; border-radius: 15px;">
  <h3> Overview </h3>
  <p>For the final project I decided to implement the approach presented in the paper: <br>
  <br> <i>Leibe, B., Leonardis, A., Schiele, B. "Combined Object Categorization and Segmentation with an Implicit Shape Model", 2004.</i>  
  </p>
  <h3>Paper Summary</h3>
  <p>
  The paper presents an approach to using patches and unsupervised learning to produce an implicit shape model, by extending the Hough Transform.  It further uses that method to both categorize and segment objects in the image.
  </p>
  <p>
  The paper proposes accomplishing this in these major steps: codebook generation from the training image set, implicit shape modeling using the codebook on the training image set, identification of codebook entries and reconstruction of the implicit shape model on the test image using a Hough transform, and segmentation of the test images.
  <p>
  To generate the codebook, first interest points are found in the training images using the Harris interest point detector.  Patches are extracted at each of the interest points, and all patches are clustered using a bottom-up agglomerative (non-parametric) clustering.  The agglomeration step is done using an similarity metric over the patches that incorporates the "Normalized Greyscale Correlation".  Patches are clustered if their similarity is over a manually chosen threshold.
  Once the patches have been clustered, a cluster center is found, and this is used to represent the patches in that cluster in future steps.
  <p>
  To construct an implicit model, the codebook is used to run over the training images again, and any patches that match the cluster centers, at least as well as the previously selected cluster threshold, are used in the implicit model.  To create the implicit model, any matching patch locations with respect to object center are saved corresponding with that codebook.
  <p>
  Those codebook centers are then applied to patches at and around the Harris interest points of the test image.  If they are similar enough (using the same threshold), the corresponding object centers are marked.  Note that this requires the objects to be about the same scale in the training and test images.
  <p> 
  The paper uses a continuous Hough space and finds maxima in Hough space using mean-shift mode finding, a non-parametric density estimator.  The maxima indicate object centers, from which object extent can be derived.
  <p>
  After finding the object centers, the same codebook features can be used to trace out object segmentations.

  <h3>Project Scope</h3>
  <p>
  For the purposes of this project, I've decided to implement some of the primary ideas in the paper.  <br>
  <br>Specifically:
  <ul>
  <li> Using agglomerative clustering on image patches taken at key points in the image to construct feature groups.
  <br>
  <li> Applying the Hough transform using with those feature groups to identify the center and extent of an object, using an implicit shape model.
  </ul>
</div>
    
</div>
</div>
<br><br>
<div id="section">
<div id="section_code">
<div style="background: #ccc; padding: 9px; border-radius: 15px;">
  <h3>Code:</h3>
<ul>
<li>Code is written in matlab</li>
<li>I've included a file <a href="main.m">main.m</a> that creates all the graphs and derived images shown below.</li>
</ul>
<h3>Clustering</h3>
<ul>
<li><a href="preprocess_cars.m">preprocess_cars.m</a> - reads images in, resamples to a larger size, and saves as .mat for fast loading at later stages.</li>
<li><a href="extract_patches.m">extract_patches.m</a> - extracts all the patches in an image set </li>
<li><a href="extract_patch.m">extract_patch.m</a> - extracts a single patch in an image set </li>
<li><a href="agglomerative_cluster.m">agglomerative_cluster.m</a> - clusters the patches using a bottom up agglomerative approach.</li>
<li><a href="similarity.m">similarity.m</a> - cluster similarity measure, as defined in the paper.</li>
<li><a href="ngc.m">ngc.m</a> - normalized greyscale correlation, for measuring similarity among pataches, as defined in the paper.</li>
</ul>
<h3>Codebook</h3>
<li><a href="create_codebook.m">create_codebook.m</a> - generates the codebook center and implicit shape model from the clusters.</li>
<li><a href="cluster_center.m">cluster_center.m</a> - calculates the center of a cluster using standard mean computation.</li>
<li><a href="cluster_center_frechet.m">cluster_center_frechet.m</a> - calculates the center of a cluster using a frechet mean-like computation - ie the patch most similar all patches in the cluster becomes the center.</li>
<h3>Locating Objects</h3>
<li><a href="hough_coverage.m">hough_coverage.m</a> - generates the hough accumulator image from the codebook and implicit shape model.</li>
<li><a href="codebook_matches.m">codebook_matches.m</a> - finds all of the matching codebooks and adds any corresponding center locations to the accumulator.</li>
<li><a href="extract_patches_neighbors.m">extract_patches_neighbors.m</a> - same as extract patches above, but also extracts neighboring pixel patches.</li>
<h3>Analysis</h3>
<li><a href="show_clusters.m">show_clusters.m</a> - utility for showing members of a cluster - for manual review of quality.  Especially useful in determining a cluster threshold.</li>
<li><a href="show_test.m">show_test.m</a> - utility for showing result of locating an object in the image - this is essentially the end goal of the rest of the scripts.  This shows the image, keypoint locations, the hough space accumulator, and the resulting max chosen.</li>
<li><a href="drawpoints.m">drawpoints.m</a> - utility for drawing points on an image - used for showing key point locations.</li>
<h3>External</h3>
(external code used in this project)
<li><a href="external/keypointExtraction/kp_harris.m">kp_harris.m</a> - extracts the harris keypoints</li>
<li><a href="external/imresample/imresample.m">imresample.m</a> - image resampling method, used for cubic resampling functionality.</li>
</div>
</div>
<br>
<div id="section">
<div style="background: #ccc; padding: 9px; border-radius: 15px;">
<b style="padding-top: 10px;">Code Description</b>
<p>
I've created a hough function that takes an edge image and the range of $\theta$ values, from the theta values it determines how large of an accumulator image is needed, for simplicity the resolution of the $\rho$ values are set to the same (accumulator is a square image).

The accumulator is generated by iterating over all $\theta$, and calculating $\rho=x cos \theta + y sin \theta$ for each x,y edge point.
</p>
<p>
A second hough_decrement function was created to run a second "decrement" phase, as described in [1].
</p>
<p>
I've made use of my previous edge detection and image smoothing code, as indicated above.  I've copied the edge detection and rescaling (for viewing) functions from the previous edge detection project.
</p>
</div>
</div>
<div id="section">
<h3>EXAMPLES:</h3>
<p>
All images shown here are form the UIUC Car Data Set: <a href="http://cogcomp.cs.illinois.edu/Data/Car/">http://cogcomp.cs.illinois.edu/Data/Car/</a>.
</p>
<table>
<tr><td><img id="image" src="images/shapes.png"><br>Original</td><td></td></tr>
<tr><td><img id="image" src="images/shapes_edge.png"><br>Edge map</td><td><img id="image" src="images/shapes_accum.png"><br>Accumulation image ($\theta$ on x-axis, $\rho$ on y-axis)</td></tr>
<tr><td colspan="2">
    <p>
    The above example shows the hough transform for a straight line applied to the edge map of the image with shapes above.  As you can see the accumulator image shows the curves in parameter space representing each of the points on the edge map.
    <p>
    We haven't done any thresholding to the edge map because it is already so clean.
</td></tr>
<tr><td><img id="image" src="images/runway.png"><br>Original</td><td></td></tr>
<tr><td><img id="image" src="images/runway_edge_orig.png"><br>Edge map</td><td><img id="image" src="images/runway_accum_orig.png"><br>Accumulation image ($\theta$ on x-axis, $\rho$ on y-axis)</td></tr>
<tr><td><img id="image" src="images/runway_edge.png"><br>Edge map, with threshold set to 0.3*maximum.</td><td><img id="image" src="images/runway_accum.png"><br>Accumulation image ($\theta$ on x-axis, $\rho$ on y-axis)</td></tr>
<tr><td colspan="2">
    <p>
    Here we see the hough transform for a straight line applied to the edge map of the image with a runway shown above.  Again, the accumulator image shows the curves in parameter space representing each of the points on the edge map. Because this is a real photograph, the edge map has a lot more noise, which causes the accumulator curves to be much less distinct, the process also takes much longer to complete.
    <p>
    To address this problem, we threshold the edge map, to only get the more strong edges, and ignore the weak edges (which will also includes most of the noise). Here we threshold at 0.3*maximum edge value. The result is shown above, as you can see the majority of the runway edge data is still there, but most of the less useful edge and noise data have been removed.  The resulting accumulator image is also much more clean - the individual curves are now distinguishable.
</td></tr>

<tr><td colspan="2">
<h3 style="padding-top: 15px;">Raw Accumulator</h3>
</td></tr>
<tr><td><img id="image" src="images/shapes_accum_points_0.9.png"><br>Maxima (red dots) detected using 0.9*maximum <br>value(dots have been enlarged). (6 maxima)</td><td><img id="image" src="images/shapes_lines_0.9.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.9*maximum).</td></tr>
<tr><td><img id="image" src="images/shapes_accum_points_0.7.png"><br>Maxima (red dots) detected using 0.7*maximum value (47 maxima).</td><td><img id="image" src="images/shapes_lines_0.7.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.7*maximum)</td></tr>
<tr><td colspan="2">
    <p>The above maxima were found without any gaussian blurring of the accumulator, or decrementation.  These are just the maxima of the simple hough transform.  As you can see the process seems to capture the lines and edges pretty well.  If we turn the threshold on the accumulation image down to 0.7*maximum value even more edges are captured.
</td></tr>
<tr><td><img id="image" src="images/runway_accum_points_0.90.png"><br>Maxima (red dots) detected using 0.9*maximum <br>value(dots have been enlarged). (3 maxima)</td><td><img id="image" src="images/runway_lines_0.90.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.9*maximum).</td></tr>
<tr><td><img id="image" src="images/runway_accum_points_0.50.png"><br>Maxima (red dots) detected using 0.5*maximum value (32 maxima).</td><td><img id="image" src="images/runway_lines_0.50.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.5*maximum)</td></tr>
<tr><td colspan="2">
    <p>
    Similarly, here we are finding the maximum on the raw accumulator without any smoothing or decrementing.  As the image shows we are able to capture the main verticle lines of the runway (which is encouraging, since those are the same lines found in the text book on p.737).  If we lower the threshold on the accumulator we are able to find more lines, including the diagonal runway edges, which is cool.
</td></tr>

<tr><td colspan="2">
<h3 style="padding-top: 15px;">Gaussian Blurring on Accumulator</h3>
</td></tr>
<tr><td><img id="image" src="images/shapes_accum_blurred_points_0.95.png"><br>Maxima (red dots) detected using 0.95*maximum <br>value(dots have been enlarged). (4 maxima)</td><td><img id="image" src="images/shapes_blurred_lines_0.95.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.95*maximum)</td></tr>
<tr><td><img id="image" src="images/shapes_accum_blurred_points_0.9.png"><br>Maxima (red dots) detected using 0.9*maximum value (26 maxima).</td><td><img id="image" src="images/shapes_blurred_lines_0.9.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.9*maximum)</td></tr>
<tr><td colspan="2">
    <p>The above maxima were found using gaussian blurring with $\sigma=1$ of the accumulator. With the blurring, more points were closer the the global maximum value (using .9*maximum as threshold still had 26 matches).  This makes sense, as the maximum has probably been lowered by the blurring, and other values may have been increased.
</td></tr>
<tr><td><img id="image" src="images/runway_accum_blurred_points_0.95.png"><br>Maxima (red dots) detected using 0.95*maximum <br>value(dots have been enlarged). (5 maxima)</td><td><img id="image" src="images/runway_blurred_lines_0.95.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.95*maximum)</td></tr>
<tr><td><img id="image" src="images/runway_accum_blurred_points_0.9.png"><br>Maxima (red dots) detected using 0.9*maximum value (9 maxima).</td><td><img id="image" src="images/runway_blurred_lines_0.9.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.9*maximum)</td></tr>
<tr><td colspan="2">
    <p>Similarly, the above maxima were found using gaussian blurring with $\sigma=1$ of the accumulator. However one interesting difference is that the blurring doesn't seem to have as drastic an effect on the number of extrema found at the threshold.  In this case at 0.9*maximum found 5 instead of 3 (for the shapes image it changed from 6 to 26).
</td></tr>

<tr><td colspan="2">
<h3 style="padding-top: 15px;">Decrementor on Accumulator</h3>
</td></tr>
<tr><td><img id="image" src="images/shapes_accum_decr_points_0.9.png"><br>Maxima (red dots) detected using 0.9*maximum <br>value(dots have been enlarged). (5 maxima)</td><td><img id="image" src="images/shapes_decr_lines_0.9.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.9*maximum)</td></tr>
<tr><td><img id="image" src="images/shapes_accum_decr_points_0.7.png"><br>Maxima (red dots) detected using 0.7*maximum value (18 maxima).</td><td><img id="image" src="images/shapes_decr_lines_0.7.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.7*maximum)</td></tr>
<tr><td colspan="2">
    <p>These maxima were found using the decrementation approach described in the [1]. Decremenation does a great job of cleaning up the accumulator, now very few (maxima) points are left, which makes the maxima discovery much more straightforward.  The curves are no longer visible (decremented away), but the maxima are still available.
    <p>
    The result above show taht we are able to again find more lines.  Some lines that weren't discovered in the raw or Gaussian approaches can now be discovered more easily.
</td></tr>
<tr><td><img id="image" src="images/runway_accum_decr_points_0.9.png"><br>Maxima (red dots) detected using 0.9*maximum <br>value(dots have been enlarged). (5 maxima)</td><td><img id="image" src="images/runway_decr_lines_0.9.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.9*maximum)</td></tr>
<tr><td><img id="image" src="images/runway_accum_decr_points_0.7.png"><br>Maxima (red dots) detected using 0.7*maximum value (18 maxima).</td><td><img id="image" src="images/runway_decr_lines_0.7.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.7*maximum)</td></tr>
<tr><td colspan="2">
    <p> The story is very similar for this image.  The decrementation strategy really cleans up the accumulator and we are able to find the same vertical lines in the image.
</td></tr>

<tr><td colspan="2">
<h3 style="padding-top: 15px;">Limit Accumulation using Edge Orientation</h3>
</td></tr>
<tr><td><img id="image" src="images/shapes_ori.png"><br>Orientation image.</td><td></td></tr>
<tr><td><img id="image" src="images/shapes_accum_ori_points_0.9.png"><br>Maxima (red dots) detected using 0.9*maximum <br>value(dots have been enlarged). (5 maxima)</td><td><img id="image" src="images/shapes_ori_lines_0.9.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.9*maximum)</td></tr>
<tr><td><img id="image" src="images/shapes_accum_ori_points_0.7.png"><br>Maxima (red dots) detected using 0.7*maximum value (23 maxima).</td><td><img id="image" src="images/shapes_ori_lines_0.7.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.7*maximum)</td></tr>
<tr><td colspan="2">
    <p>
    Another approach to speeding up the accumulation step is to limit the $\theta$ parameter using the edge orientation of the edge points.  The resulting accumulation image is shown above.  It's interesting to note that while we are limiting $\theta$ (x-axis) the most drastic/noticeable breaks in the curves is along the $\rho$ parameter (y-axis).
    <p>
    The approach appears successful, as you can see above the appropriate lines are detected again, but with much less computation.  If we lower the threshold we find additional lines like before. 
</td></tr>
<tr><td><img id="image" src="images/runway_ori.png"><br>Orientation image.</td><td></td></tr>
<tr><td><img id="image" src="images/runway_accum_ori_points_0.9.png"><br>Maxima (red dots) detected using 0.9*maximum <br>value(dots have been enlarged). (1 maxima)</td><td><img id="image" src="images/runway_ori_lines_0.9.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.9*maximum)</td></tr>
<tr><td><img id="image" src="images/runway_accum_ori_points_0.7.png"><br>Maxima (red dots) detected using 0.7*maximum value (4 maxima).</td><td><img id="image" src="images/runway_ori_lines_0.7.png"><br>Lines corresponding to the maxima shown the left (threshold of 0.7*maximum)</td></tr>
<tr><td colspan="2">
    <p> 
    The results for this image are very similar. We are able to compute the accumulator image very quickly, but the results are largely successful.  In this particular instance we only get one of the vertical edges.  
</td></tr>



</table>

</div>
</body>
</html>
